{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Connor McManigal\n",
    "- Donggyu(Alex) Yu\n",
    "- Jungwoo(Kevin) Park\n",
    "- Shivani Suthar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This project aims to solve the difficulty associated with making accurate diagnoses of diabetes in patients. If a patient is incorrectly diagnosed, it could lead to dire consequences, such as additional health issues or even death. Our goal is to solve this problem by designing machine learning algorithms that will accurately predict whether a patient has diabetes. Our data encompasses eight features such as age, gender, body mass index(BMI), hypertension, heart disease, smoking history, HbA1c levels, and blood glucose levels, along with their diabetes status: positive or negative. These electronic health records are collected through surveys, medical records, and laboratory tests from individuals by healthcare providers in hospitals or clinics. With this data, we will train multiple binary classification algorithms and select the algorithm that provides the highest sensitivity. We will compare the performances of logistic regression, decision tree, k-nearest neighbor, and support vector machines to see which algorithm best suits our needs. We will measure performance using sensitivity, precision, specificity, ROC-AUC, and precision-recall curves with a heavy emphasis on high recall, as it is important to detect all the positive diabetes cases in order to provide immediate treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Health-related issues have significant impacts on the lives of countless individuals and families worldwide. Among these issues, diabetes has emerged as a disease that is incurable and can only be treated. According to the World Health Organization (WHO), about 422 million people across the world are suffering from diabetes and the majority of them come from low or middle income countries. More devastatingly, about 1.5 million individuals face death because of diabetes<a name=\"WHO\"></a>[<sup>[1]</sup>](#WHO). When diabetes goes untreated, it could also result in other medical issues such as heart disease or stroke. Despite the availability of improved medical treatments, the true extent of diabetes often remains concealed in our daily lives. While medicinal advancements have improved diabetes treatment, there is still no cure and this leaves many individuals and families struggling with the long-term consequences. The insidious nature of diabetes further complicates its identification and detection. Another fact about diabetes is that there are two different types: type I and type II. The significant difference between type one and type two diabetes is that type one diabetes shows during adolescence and is genetically inherited; in which the pancreas does not make insulin at all. On the other hand, type two diabetes patients' experience less insulin production and it develops throughout life, typically showing up in adulthood. This makes it especially difficult to diagnose diabetes because both genetic and environmental components such as diet or exercise can be involved.<a name=\"diabetesUK\"></a>[<sup>[2]</sup>](#diabetesUK) Additionally, the symptoms of diabetes often overlap with those of other diseases, making early detection challenging. Common early signs of diabetes include fatigue and extreme hunger <a name=\"SMC\"></a>[<sup>[3]</sup>](#SMC). However, due to their subtle nature and resemblance to symptoms of other diseases, they frequently go unnoticed or are misattributed, making it hard for timely diagnosis. \n",
    "\n",
    "Due to the above reasons, numerous studies have been conducted to reliably identify diabetes using machine learning algorithms. Harleen Kaur and Vinita Kumari conducted research on predicting diabetes using linear SVM and radial basis kernel SVM, achieving an accuracy score of 89 percent with high recall and precision scores <a name=\"Kaur&Kumari\"></a>[<sup>[4]</sup>](#Kaur&Kumari). Additionally, Apanig et al. utilized SVM to implement Artificial Intelligence, suggesting its potential to interact with patients and provide diabetes diagnoses, thus potentially overcoming the limitations of in-person consultations with doctors (cite). Inspired by these researchers' innovative approaches and real-life examples, we aim to contribute further to the accurate diagnosis of diabetes<a name=\"Spanig\"></a>[<sup>[5]</sup>](#Spanig)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "People suffer from diabetes when their body fails to produce enough insulin or cannot properly use insulin to turn glucose into energy. This typically results in high blood glucose levels and this dramatically increases the risk of heart diseases, stroke, kidney diseases, eye problems, dental diseases, nerve damage, and even foot problems. Other symptoms can include frequent urination, fatigue, slow healing, extreme thirst, and weight loss. These warning signs can easily be overlooked and often overlap with other minor health problems. Some accurate medical indicators for evaluating susceptibility for diabetes include body mass index (BMI), hypertension, heart disease, smoking history, HbA1c levels, and blood glucose levels. Despite diabetes' serious nature, early detection followed by change of habits and proper medications can significantly lower the risk of serious diseases. We plan to solve this problem by classifying patients with diabetes based on their medical records in conjunction with some of their demographic information through multiple ML-algorithms: decision trees, k-nearest neighbors, logistic regressions, and support vector machines. This problem is quantifiable as a binary classification; positive class means that the patient has diabetes and negative class depicts that the patient does not have diabetes. Our metrics for evaluating the performance of these algorithms will include sensitivity, precision, specificity, ROC-AUC, and precision-recall curve with heavy emphasis on high sensitivity, as it is important to detect patients who have diabetes in order for them to receive immediate treatment. This problem is highly replicable because diabetes is found across the globe and it commonly has different precursors depending on individual health differences. We think that there could be additional features that would help us properly label patients with diabetes such as additional demographic information, how regularly someone exercises, and what their diet consists of. Through our implementation of various machine learning techniques, we believe we can train successful models that will predict patients with diabetes from data containing new individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We have located a diabetes dataset from kaggle that includes 7 numerical variables, 2 categorical variables, and 100,000 observations. Amongst the 7 numeric variables, we have the patients’ age, body mass index(BMI), HbA1c level, blood glucose level, and binaries describing whether or not they had hypertension, heart disease, or diabetes. Our two categorical variables include the patient’s gender with 3 unique categories (male/female/other) and smoking history with six unique categories (never/no info/current/former/ever/not current). We feel that this is an adequate amount of observations and variables to utilize machine learning to perform this binary classification task.\n",
    "- Link: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset\n",
    "- Dataset size: 100,000 x 9 = 100,000 observations and 9 variables(8 when not including our diabetes truth label)\n",
    "- A single observation consists of a single “patient” and each row contains a pateints’ respective age, body mass index(BMI), HbA1c level, blood glucose level, gender, smoking history, as well as hypertension, heart disease, and diabetes information(denoted as 0’s or 1’s). \n",
    "- We think that all the variables besides the diabetes binary will be integral when training. We think that an individual’s age, BMI, HbA1c level, blood glucose level, smoking history, gender, and hypertension as well as heart disease information will all contribute close to equal value to our predictive accuracy. The ninth variable, or the ‘diabetes’ variable will serve as our truth label within the data. After conducting a rough exploratory data analysis on the data, we found that 8.5% of the 100,000 individuals within the data contain diabetes of some sort(either diabetes I or II). Interestingly, this sample has a similar diabetes rate to the US, which is roughly 11.3% of the population. \n",
    "- Also, this data set is extremely tidy and contains no missing values. We used the skimr R package to analyze our variables’ missingness, distinct values, and for numerics, maximum and minimum values. With that being said, two variables and their distinct values stood out to us most: age and smoking history. The age variable, represented as a numeric, contains values from 0.08 to 80.0. This means that the data contains patients from roughly 1 month old to 80 years old. As of now, we will leave this variable be, but we may end up narrowing down our analysis to a specific age group. In respect to smoking history, there are 6 unique categories and they include never, no info, current, former, ever, and not current. On kaggle there isn’t a data dictionary listed, so we weren’t sure what the difference was between some of the categories(i.e. “not current” versus “former”), however, we found better descriptions under the discussion section. We will most likely leave this feature as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Since we want to correctly predict diabetes and not allow those with diabetes to be misclassified, we desire a high true positive rate and a low false negative rate for our binary classification. In order to do this, we will utilize an individual’s features such as age, gender, body mass index(BMI), hypertension, heart disease, smoking history, HbA1c levels, and blood glucose levels. To start, it is necessary that our data is ready for proper implementation in our algorithms and this means we will have to standardize the data by z-scoring or using scalars on the data(i.e. ‘age’ ranges from 0.08 to 80 which is a relatively large gap). In addition, we will also one-hot encode our categorical features(i.e. ‘gender’ and ‘smoking history’). \n",
    "\n",
    "We will seek to find the best performing algorithm by utilizing cross-validation on our hyperparameters. Since our number of observations is large(100,000 rows), we will most likely not be able to use Grid Search. We should note that Grid Search would be ideal in this situation, however, it is typically not feasible on large amounts of data. So, if our implementation of Grid Search fails, we plan to use Random Search to tune for the best hyperparameters for each of our algorithms: logistic regression, k-nearest neighbor, support vector machine, and decision tree. After finding the best hyperparameters for each algorithm, we will be able to compare each algorithm’s accuracy scores. We will also consider evaluation metrics. More specifically, we do not want our models to falsely classify diabetes and we desire our models to minimize the number of false negatives(falsely classifying as negative could result in a patient going untreated). So we will take a look at each algorithm's sensitivity, false negative rate, and visually analyze the ROC-AUC curves to compare and contrast algorithms. Note that we want our models to provide high sensitivity or recall, all while maintaining low false negative rates.\n",
    "\n",
    "To implement each algorithm, we will first need to perform a train-test split on the data. We will use Sklearn libraries to split our data into training and testing, and use those separated datasets according to each algorithm. The Grid search(or Random search) will have a k value as an argument which will split the train and hold out sets to carry out fit and test errors. So we will use k=5 across all Grid Searches (or Random Searches). We do not need to go through feature selection (PCA) because we are pretty limited on our variables and the variables that we do have are extremely relevant for making diabetes diagnoses.\n",
    "\n",
    "We found a similar benchmark in line with our approach which showed 96.99% accuracy using ANN(Artificial Neural Network), however, this benchmark did not tune the hyperparameters. Despite this, we think this benchmark could serve as a good comparison after we tune the hyperparameters using Grid or Random search <a name=\"Garg\"></a>[<sup>[6]</sup>](#Garg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For our specific binary diabetes classification problem, we want our algorithm(s) to accurately classify the true positives within the data while minimizing the number of false negatives. Specifically, we want our algorithm(s) to provide a high sensitivity or recall (TP/TP + FN) and maintain a low false negative rate (FNR = 1 - TPR). The reason for this is because we don’t want our algorithm to falsely classify a patient as not having diabetes, when in reality they do. The worst case scenario is if our algorithm falsely classifies a patient as negative, when in fact they are positive. When someone gets diagnosed with diabetes, they require immediate treatment and medical attention, so it is essential that we catch all of the true positives. We will also use confusion matrices, ROC-AUC curves, and precision-recall curves to visually inspect our algorithms’ predictive accuracy and results. In regard to ROC-AUC, we want to minimize the false positives and false negatives while making sure to pick up on as many of the true positives and true negatives that we can. Also, we are going to want to maximize the area under the curve(AUC). Finally, we will analyze our algorithms’ specificity(TN/TN + FP) and precision(TP/TP + FP). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at our dataset’s website and csv file at first glance, it wouldn’t seem like there are any obvious, glaring ethics or privacy issues. However, when digging deeper, there could be potential risk of a HIPPA violation as the data we are using is medical data and on the website, there is no place that states that consent of some form was given by the patients or  participants for their medical information to be available online. On the website, it simply states “Electronic Health Records (EHRs) are the primary source of data for the Diabetes Prediction dataset…To create the Diabetes Prediction dataset, EHRs were collected from multiple healthcare providers and aggregated into a single dataset… The collection methodology for the diabetes prediction dataset involves gathering medical and demographic data from patients who have been diagnosed with or are at risk of developing diabetes. The data is typically collected through surveys, medical records, and laboratory tests…” Clearly, medical information was gathered from real patients but it did not state what the manner of consent for using the medical information was. While the data itself is fully anonymized, it could be possible that large companies or medical centers could deduce a person’s identity(or get it down to a group of people) based on the information provided in each row of the dataset. That is why we will extract only absolutely necessary data from the dataset in order to complete our project to mitigate the chances of any identity leaks. In addition, from the analysis perspective, there is a chance that maybe not all demographics of people were included in this dataset since we do not know what exact strategy the data was collected by(simple random sampling, stratified random sampling, etc.). Hence, we will be sure to acknowledge this potential pitfall in our discussion section. Lastly, we drew our dataset from Kaggle which is typically a trusted source for accurate data, but it is not a specialized medical organization, and likely not verified. So, there could be concern that the data has not been accurately collected. However, we will also be sure to acknowledge this concern in the discussion section of our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Primary method of communication will be through Discord but text messaging will be used as a backup method in case someone is facing difficulty with Discord*\n",
    "* *If there is conflict/difficulty (i.e someone is consistently not meeting deadlines, not communicating etc.), there will be a group meeting where everyone will openly and honestly discuss what to do moving forward and if any changes should be made to our proposed schedule and if there may need to be a shift in responsibility of tasks.*\n",
    "* *If people can’t decide what we want to do with a particular aspect of the project, a vote will be taken on the choices we are debating between and each member will provide some sort of a justification as to why they are voting that way and the popular vote/most justified vote will win.*\n",
    "* *We will try to stick to the proposed timeline on this proposal for our schedule but we will check in periodically across meetings to ensure that the schedule is still working for people and see if any changes may need to be implemented.*\n",
    "* *We expect that everyone will complete their pre-meeting work and any specific tasks assigned before each meeting.*\n",
    "* *Members will discuss ahead of time (at least 24 hours prior) in the Discord group chat if it might be difficult for them to meet a deadline.*\n",
    "* *For last minute unexpected emergencies, if someone is unable to complete their assigned task, then they may be given an extension, a different task, or their task may be distributed in another manner depending on the situation.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please Note: Wednesday meeting times are only listed if absolutely necessary for last minute work. If it aligns with group members, Tuesday nights may be used as catch-up days if we fall behind schedule. \n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "|Monday, 5/15/23 |  4:18 pm PST  | NA | During this meeting (our first meeting), we discussed ideas for which topic/dataset we would like to work with and tentatively decided on the kaggle diabetes dataset linked below. We also decided who will be in charge of what aspects of this project proposal. We also discussed the deadline by which we would ideally like to submit this proposal - (Tuesday, 5/16/23 11:59 pm PST)|\n",
    "| Wednesday, 5/17/23 Group - Project proposal due (assuming at 8 pm PST)| 4 - 6 pm PST (if meeting is needed)| Each member should come prepared with a list of any last minute concerns, questions, or edits they would like to make to the project proposal if we have not already submitted the proposal. (all) | Any last minute concerns, questions, or suggested edits for the project proposal that any person may have will be discussed (If proposal has not already been submitted). We will keep a goal to submit the proposal by 6 pm PST at the very, very, latest if absolutely needed. | \n",
    "| Thursday, 5/18/23  | 7 - 9 pm PST  | Each member should become familiarized with the requirements of the final project and our data set and do a little bit of background research on the topic/problem at hand. Each member should also brainstorm some additional ideas for data cleaning (beyond what’s mentioned in this proposal) if necessary. (all)  | During this meeting, each member will share what they learned about the topic/problem at hand and will share what idea they came up with for cleaning the data. Then we will decide as a group how we want to clean the data and what sections of the data and in what format we want to work with the data overall. The goal of this meeting will be to have a solid, finalized, clean section of the dataset we will work with based on the research that we did and what aspects of the dataset would be most relevant to the topic/problem at hand.   |\n",
    "| Monday, 5/22/23  | 7- 9 pm PST  | Each member should play around with the finalized version of the dataset we decided on from the previous meeting and brainstorm ideas/write preliminary code for the evaluations metrics (beyond what is written in this proposal). (all) | During this meeting, each member will share what they came up with for the evaluation metrics. Then we will decide as a group how we want to finalize the evaluation metrics and work on getting them done. The goal of this meeting will be to have a nearly completed section for our evaluation metrics with code/math if necessary |\n",
    "| Thursday, 5/25/23  | 7 - 9 pm PST | Each member should read the peer feedback we received on our project proposal and determine which suggestions they think we should implement. (all)  | During this meeting, we will discuss any suggestions people thought were important from the peer feedback forms and decide on which suggestions we want to implement as a group. We will implement those changes and also use this meeting time to finalize our evaluation metrics section if necessary.  |\n",
    "| Monday,  5/29/23  | 7 - 9 pm PST  | Each member should look over our current work for the project and come up with any suggestions they may have for our finalized project checkpoint. (all)| During this meeting, we will discuss what everyone thinks we should add/edit for our project checkpoint and work on finalizing our project checkpoint. If not completed, we will continue to work  on Tuesday and we would ideally like to have our project checkpoint submitted by Tuesday, 5/30/23 11:59 pm PST. |\n",
    "| Wednesday, 5/31/23 Group - Project checkpoint due (assuming at 8 pm PST)|4 - 6 pm PST (if meeting is needed) | Each member should come prepared with a list of any last minute concerns, questions, or edits they would like to make to the project checkpoint if we have not already submitted the project checkpoint. (all) | Any last minute concerns, questions, or suggested edits for the project checkpoint that any person may have will be discussed (If project has not already been submitted). We will keep a goal to submit the project checkpoint by 6 pm PST at the very, very, latest if absolutely needed.   |\n",
    "|Thursday, 6/1/23|7 - 9 pm PST|Each member should come up with ideas for what to include in the results sections for subsections 1-3  (all)|During this meeting, we will finalize the proposed solution section and work on the results section and try to finalize subsections 1-3 for it. |\n",
    "|Monday, 6/5/23|7 - 9 pm PST|Each member should come up with ideas for what to include in the results sections for subsections 4-5  (all)|During this meeting, we will work on the results section and try to finalize subsections 4-5 for it. We will also begin working on the discussion section.|\n",
    "|Thursday, 6/8/23|7 - 9 pm PST|Each member should continue coming up with ideas to finalize the discussion section (all)|During this meeting we will discuss everyone’s suggestions for finalizing the discussion section and aim to get it fully completed|\n",
    "|Monday, 6/12/23|7 - 9 pm PST|Each member should come up with any suggestions for changes they may want to make to our final project (all).|We will discuss any changes people may want to make to the final project and work on finalizing the project for submission including all sections from the title to the conclusion. If not finished, we will continue working on Tuesday and we would ideally like to have our final project checkpoint submitted by Tuesday, 6/13/23 11:59 pm PST.|\n",
    "|Wednesday, 6/14/23 Group - Final project due (assuming at 8 pm PST) Individual - Team evaluations surveys due (assuming at 8 pm PST) | 4 - 6 pm PST (if meeting is needed)|Each member should come prepared with a list of any last minute concerns, questions, or edits they would like to make to the final project if we have not already submitted the project. (all) |Any last minute concerns, questions, or suggested edits for the final project that any person may have will be discussed (If project has not already been submitted). We will keep a goal to submit the project by 6 pm PST at the very, very, latest if absolutely needed.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"WHO\"></a>1.[^](#WHO): World Health Organization: https://www.who.int/health-topics/diabetes#tab=tab_1. <br> \n",
    "<a name=\"diabetesUK\"></a>2.[^](#diabetesUK): Diabetes: : https://www.diabetes.org.uk/diabetes-the-basics#:~:text=The%20main%20difference%20between%20the,producing%20cells%20in%20your%20pancreas. <br>\n",
    "<a name=\"SMC\"></a>3.[^](#SMC): South Side Medical Center: https://southsidemedical.net/diabetes-management-why-is-it-important/#:~:text=Diabetes%20is%20a%20serious%20medical,%2C%20dementia%2C%20and%20kidney%20issues. <br>\n",
    "<a name=\"Kaur&Kumari\"></a>4.[^](#Kaur&Kumari): Predictive modelling and analytics for diabetes using a machine learning approach: https://www.emerald.com/insight/content/doi/10.1016/j.aci.2018.12.004/full/html.  <br>\n",
    "<a name=\"Spanig\"></a>5.[^](#Spanig): The virtual doctor: An interactive clinical-decision-support system based on deep learning for non-invasive prediction of diabetes: https://www.sciencedirect.com/science/article/pii/S0933365719301083?casa_token=cOj_UY-zjeMAAAAA:elRBENnAuVFx6T2Mk5wh0s9KE4fJF5_vokrfuxv1f_a_g8MZClm28_pSu6hkm4M6sbnnIxPp0w. <br>\n",
    "<a name=\"Garg\"></a>6.[^](#Garg): Benchmark example on Kaggle: https://www.kaggle.com/code/ishantgargml/diabetes-prediction-96-99-accuracy-ann/notebook#Our-winning-model-is-ANN-with-96.99%-accuracy.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
