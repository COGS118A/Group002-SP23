{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Connor McManigal\n",
    "- Donggyu(Alex) Yu\n",
    "- Jungwoo(Kevin) Park\n",
    "- Shivani Suthar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This project will aim to solve the difficulty associated with making accurate diagnoses of diabetes in patients. If a patient is incorrectly diagnosed, it could lead to dire consequences, such as additional health issues or even death. Our goal is to solve this problem by designing machine learning algorithms that will accurately predict whether a patient has diabetes. Our diabetes data encompasses eight features such as age, gender, body mass index(BMI), hypertension, heart disease, smoking history, HbA1c levels, and blood glucose levels, along with their diabetes status: positive or negative. These electronic health records are collected through surveys, medical records, and laboratory tests from individuals by healthcare providers in hospitals or clinics. With this data, we will train multiple binary classification algorithms and select the algorithm that provides the highest sensitivity. We will compare the performances of logistic regression, decision tree, k-nearest neighbor, and support vector machines to see which algorithm best suits our needs. We will measure performance using precision, sensitivity, specificity, ROC-AUC, and precision-recall curves with a heavy emphasis on high recall, as it is important to detect all the positive diabetes cases in order to provide immediate treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Over the past few decades, the health-related issues has significantly impacted the lives of countless individuals and families. Among these issues, diabetes has emerged as one of the most unsolvable diseases across the world. According to the World Health Organization (WHO), about 422 milion people across the world is suffering from diabetes and majority of them come from low/middle income countries. More devastating fact is that about 1.5 million individuals face death because of diabetes<a name=\"WHO\"></a>[<sup>[1]</sup>](#WHO). Untreated diabetes also could result other medical circumstances such as stroke. Despite the availability of improved medical treatments, the true extent of diabetes often remains concealed in our daily lives. While medicational advancements have improved to deal better with diabetes, a complete cure still remains unsolved, leaving many individuals and families to struggle with its long-term consequences. The insidious nature of diabetes further complicates its identification and detection. The symptoms of diabetes often overlap with those of other diseases, making early detection challenging. Common early signs of diabetes include fatigue and an extreme hunger<a name=\"SMC\"></a>[<sup>[2]</sup>](#SMC). However, due to their subtle nature and resemblance to symptoms of other disease, they frequently go unnoticed or are misattributed, making hard for timely diagnosis. \n",
    "\n",
    "Due to the above reasons, numerous studies have been conducted to reliably identify diabetes using machine learning algorithms. Harleen Kaur and Vinita Kumari conducted research on predicting diabetes using linear SVM and radial basis kernel SVM, achieving an accuracy score of 89 percent with high recall and precision scores <a name=\"Kaur&Kumari\"></a>[<sup>[3]</sup>](#Kaur&Kumari). Additionally, Spanig et al. utilized SVM to implement Artificial Intelligence, suggesting its potential to interact with patients and provide diabetes diagnoses, thus potentially overcoming the limitations of in-person consultations with doctors (cite). Inspired by these researchers' innovative approaches and real-life examples, we aim to contribute further to the accurate diagnosis of diabetes.<a name=\"Spanig\"></a>[<sup>[4]</sup>](#Spanig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "People suffer from diabetes when the body fails to produce enough insulin or cannot properly use insulin to turn glucose in the food to get used as energy in the cell. This results in high blood glucose level which highly increases the risk of heart diseases, stroke, kidney disease, eye problems, dental disease, nerve damage, and even foot problems. Although symptoms like frequent urination, fatigue, slow healing, extreme thirst, and weight loss exist, these warning signs can easily be overlooked and overlap with other minor health problems. More accurate medical indicators for evaluating susceptibility for diabetes include body mass index (BMI), hypertension, heart disease, smoking history, HbA1c level, and blood glucose level. Despite its fatality, early detection followed by change of habits and proper medications can significantly lower the risk of serious diseases. We plan to solve this problem of people by accurately classifying patients with diabetes based on their medical record as well as demographic information using ML-algorithms: decision tree, k-nearest neighbor, logistic regression or support vector machine. The problem is quantifiable as binary classification; a positive class is that the patient has diabetes and a negative class is that the patient does not have diabetes. The metric for measuring performance will be precision, sensitivity, specificity, ROC-AUC, and precision-recall curve with heavy emphasis on high recall rate as it is important to detect patients who have diabetes for immediate treatments. The problem is highly replicable because diabetes is commonly found among multiple individuals around the globe with different precursors depending on individual health differences. There could be more features that indicate diabetes which would be dependent on the span of the dataset, about potential patients, we have access to. By implementing machine learning techniques to diverse datasets containing different individual health records, we can train models to predict diabetes in new medical data of newly introduced individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We have found a diabetes dataset from kaggle that includes 7 numerical variables, 2 categorical variables, and 100,000 observations. Amongst the 7 numeric variables, we have patient age, body mass index(BMI), HbA1c levels, blood glucose levels, and binaries describing whether or not the respective patient had hypertension, heart disease, and diabetes. Our two categorical variables include the patient’s gender with 3 unique categories (male/female/other) and smoking history with six unique categories (never/no info/current/former/ever/not current). We feel that this is an adequate amount of observations and variables to utilize machine learning to perform this binary classification task.\n",
    "- Link: https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset\n",
    "- Dataset size: 100,000 x 9 = 100,000 observations and 9 variables(8 when not including the diabetes binary)\n",
    "- A single observation consists of a single “patient” and each row contains a pateints’ respective age, body mass index(BMI), HbA1c level, blood glucose level, gender, smoking history, and hypertension, heart disease, and diabetes information(as 0’s or 1’s). \n",
    "- We think that all the variables besides the diabetes binary will be integral when training. We think that an individual’s age, BMI, HbA1c level, blood glucose level, smoking history, gender, and hypertension as well as heart disease information will all contribute close to equal value to our predictive accuracy. The ninth variable, or the ‘diabetes’ variable will serve as our truth label within the data. After conducting a rough exploratory data analysis on the data, we found that 8.5% of the 100,000 individuals within the data contain diabetes of some sort(either diabetes I or II). Interestingly, this sample has a similar diabetes rate to the US, which is roughly 11.3% of the population. \n",
    "- Also, this data set is extremely tidy and contains no missing values. We used the skimr R package to analyze our variables’ missingness, distinct values, and for numerics, maximum and minimum values. With that being said, two variables and their distinct values stood out to us most: age and smoking history. The age variable, represented as a numeric, contains values from 0.08 to 80.0. This means that the data contains patients from roughly 1 month old to 80 years old. As of now, we will leave this variable be, but we may end up narrowing down our analysis to a specific age group. In respect to smoking history, there are 6 unique categories and they include never, no info, current, former, ever, and not current. On kaggle there isn’t a data dictionary listed, so we weren’t sure what the difference was between some of the categories(i.e. “not current” versus “former”), however, we found better descriptions under the discussion section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Since correctly predicting diabetes (having higher true positive) and not falsely predicting (having lower false positive) is essential, we would like an algorithm that could best perform on binary classification on predicting diabetes. To do so, we will utilize individual’s diabetes features such as age, gender, body mass index(BMI), hypertension, heart disease, smoking history, HbA1c levels, and blood glucose levels (column variables). In order to do that, we need our data ready for implementation of linear calculation for implementing binary classification, which means we will have to scale diabetes data (standardize data, for example, age variable ranges from 0.08 to 80 which have relatively large gap), and one-hot encode the categorical data (e.g., smoking is categorical variable). \n",
    "\n",
    "We seek to find best performance by utilizing cross-validation on each algorithms. Since the observation size is large (100,000 observations), we might not be able to use Grid Searh, so if given time does not allow us to use Grid Search, we will use Random Search to tune for the best hyperparameter for Logistic regression, K-NN, SVM and Decision tree and compare for the best possible performance. Additionally, we do not want a model that will have falsely classify diabetes (falsely classifying diabetes could result a patient to miss diabetes and go untreated - false negative) and want a model that keeps high sensitivity or recall and lower false negative rate. So will find best hyper parameter that cares high sensitivity and lower false negative rate.\n",
    "\n",
    "To implement each algorithms, we first need to train-test split. We will use Sklearn libraries to split our data into training and testing, and use those separated datasets accordingly to each algorithms. The Grid search(or Random search) will have k value as an argument which will split the train and hold out set to carry out fit and test errors. So we will use k=5 across all Grid search (or Random search). We do not need to go through feature selection (PCA) because we are pretty limited on our variables and most variables are relevant to diabetes\n",
    "\n",
    "There was similar benchmark to our approach which showed 96.99 accuracy using ANN (Artificial Neural Network), however, this benchmark did not tune the hyperparameters so this benchmark could be a good comparison for us to compare after tuning the hyperparameters using Grid or Random search.<a name=\"Garg\"></a>[<sup>[5]</sup>](#Garg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For our specific binary diabetes classification problem, we want our algorithm(s) to accurately classify the true positives within the data while minimizing the number of false negatives. Specifically, we want our algorithm(s) to provide a high sensitivity or recall (TP/TP + FN) and maintain a low false negative rate (FNR = 1 - TPR). The reason for this is because we don’t want our algorithm to falsely classify a patient as not having diabetes, when in reality they do. The worst case scenario is if our algorithm falsely classifies a patient as negative, when in fact they are positive. When someone gets diagnosed with diabetes, they require immediate treatment and medical attention, so it is essential that we catch all of the true positives. We will also use confusion matrices, ROC-AUC, and precision-recall curves to visually inspect our algorithms’ predictive accuracy and results. In regard to ROC-AUC, we want to minimize the false positives and false negatives while making sure to pick up as many of the true positives and true negatives as we can. Also, we are going to want to maximize the area under the curve(AUC). Finally, we will analyze our algorithms’ specificity(TN/TN + FP) and precision(TP/TP + FP). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at our dataset website and csv file at first glance, it wouldn’t seem like there are any obvious, glaring ethics/privacy issues. However, when digging deeper, there could be potential risk of a HIPPA violation as the data we are using is medical data and on the website, there is no place that states that consent of some form was given by the patients/survey participants for their medical information to be used online. On the website, it simply states “Electronic Health Records (EHRs) are the primary source of data for the Diabetes Prediction dataset…To create the Diabetes Prediction dataset, EHRs were collected from multiple healthcare providers and aggregated into a single dataset… The collection methodology for the diabetes prediction dataset involves gathering medical and demographic data from patients who have been diagnosed with or are at risk of developing diabetes. The data is typically collected through surveys, medical records, and laboratory tests…” Clearly, medical information was gathered from real patients but it did not state if/what the manner of consent for using the medical information was. While the data itself is fully anonymized, it could possible that large companies or medical centers could deduce a person’s identity (or get it down to a group of people) based on the information provided in each row of the dataset. That is why we will extract only absolutely necessary data from the dataset in order to complete our project to mitigate the chances of any identity leaks. In addition, from the analysis perspective, there is a chance that maybe not all demographics of people were included in this dataset since we do not know what exact strategy (simple random sampling, stratified random sampling, etc.) the data was collected by. Hence, we will be sure to acknowledge this potential pitfall in our discussion section. Lastly, we drew our dataset from Kaggle which while is typically a trusted source for accurate data, it is not a specialized medical organization/website and likely not verified so there could be the concern that the data has not been fully accurately collected. However, we will also be sure to acknowledge this concern in the discussion section of our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Primary method of communication will be through Discord but text messaging will be used as a backup method in case someone is facing difficulty with Discord*\n",
    "* *If there is conflict/difficulty (i.e someone is consistently not meeting deadlines, not communicating etc.), there will be a group meeting where everyone will openly and honestly discuss what to do moving forward and if any changes should be made to our proposed schedule and if there may need to be a shift in responsibility of tasks.*\n",
    "* *If people can’t decide what we want to do with a particular aspect of the project, a vote will be taken on the choices we are debating between and each member will provide some sort of a justification as to why they are voting that way and the popular vote/most justified vote will win.*\n",
    "* *We will try to stick to the proposed timeline on this proposal for our schedule but we will check in periodically across meetings to ensure that the schedule is still working for people and see if any changes may need to be implemented.*\n",
    "* *We expect that everyone will complete their pre-meeting work and any specific tasks assigned before each meeting.*\n",
    "* *Members will discuss ahead of time (at least 24 hours prior) in the Discord group chat if it might be difficult for them to meet a deadline.*\n",
    "* *For last minute unexpected emergencies, if someone is unable to complete their assigned task, then they may be given an extension, a different task, or their task may be distributed in another manner depending on the situation.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please Note: Wednesday meeting times are only listed if absolutely necessary for last minute work. If it aligns with group members, Tuesday nights may be used as catch-up days if we fall behind schedule. \n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "|Monday, 5/15/23 |  4:18 pm PST  | NA | During this meeting (our first meeting), we discussed ideas for which topic/dataset we would like to work with and tentatively decided on the kaggle diabetes dataset linked below. We also decided who will be in charge of what aspects of this project proposal. We also discussed the deadline by which we would ideally like to submit this proposal - (Tuesday, 5/16/23 11:59 pm PST)|\n",
    "| Wednesday, 5/17/23 Group - Project proposal due (assuming at 8 pm PST)| 4 - 6 pm PST (if meeting is needed)| Each member should come prepared with a list of any last minute concerns, questions, or edits they would like to make to the project proposal if we have not already submitted the proposal. (all) | Any last minute concerns, questions, or suggested edits for the project proposal that any person may have will be discussed (If proposal has not already been submitted). We will keep a goal to submit the proposal by 6 pm PST at the very, very, latest if absolutely needed. | \n",
    "| Thursday, 5/18/23  | 7 - 9 pm PST  | Each member should become familiarized with the requirements of the final project and our data set and do a little bit of background research on the topic/problem at hand. Each member should also brainstorm some additional ideas for data cleaning (beyond what’s mentioned in this proposal) if necessary. (all)  | During this meeting, each member will share what they learned about the topic/problem at hand and will share what idea they came up with for cleaning the data. Then we will decide as a group how we want to clean the data and what sections of the data and in what format we want to work with the data overall. The goal of this meeting will be to have a solid, finalized, clean section of the dataset we will work with based on the research that we did and what aspects of the dataset would be most relevant to the topic/problem at hand.   |\n",
    "| Monday, 5/22/23  | 7- 9 pm PST  | Each member should play around with the finalized version of the dataset we decided on from the previous meeting and brainstorm ideas/write preliminary code for the evaluations metrics (beyond what is written in this proposal). (all) | During this meeting, each member will share what they came up with for the evaluation metrics. Then we will decide as a group how we want to finalize the evaluation metrics and work on getting them done. The goal of this meeting will be to have a nearly completed section for our evaluation metrics with code/math if necessary |\n",
    "| Thursday, 5/25/23  | 7 - 9 pm PST | Each member should read the peer feedback we received on our project proposal and determine which suggestions they think we should implement. (all)  | During this meeting, we will discuss any suggestions people thought were important from the peer feedback forms and decide on which suggestions we want to implement as a group. We will implement those changes and also use this meeting time to finalize our evaluation metrics section if necessary.  |\n",
    "| Monday,  5/29/23  | 7 - 9 pm PST  | Each member should look over our current work for the project and come up with any suggestions they may have for our finalized project checkpoint. (all)| During this meeting, we will discuss what everyone thinks we should add/edit for our project checkpoint and work on finalizing our project checkpoint. If not completed, we will continue to work  on Tuesday and we would ideally like to have our project checkpoint submitted by Tuesday, 5/30/23 11:59 pm PST. |\n",
    "| Wednesday, 5/31/23 Group - Project checkpoint due (assuming at 8 pm PST)|4 - 6 pm PST (if meeting is needed) | Each member should come prepared with a list of any last minute concerns, questions, or edits they would like to make to the project checkpoint if we have not already submitted the project checkpoint. (all) | Any last minute concerns, questions, or suggested edits for the project checkpoint that any person may have will be discussed (If project has not already been submitted). We will keep a goal to submit the project checkpoint by 6 pm PST at the very, very, latest if absolutely needed.   |\n",
    "|Thursday, 6/1/23|7 - 9 pm PST|Each member should come up with ideas for what to include in the results sections for subsections 1-3  (all)|During this meeting, we will finalize the proposed solution section and work on the results section and try to finalize subsections 1-3 for it. |\n",
    "|Monday, 6/5/23|7 - 9 pm PST|Each member should come up with ideas for what to include in the results sections for subsections 4-5  (all)|During this meeting, we will work on the results section and try to finalize subsections 4-5 for it. We will also begin working on the discussion section.|\n",
    "|Thursday, 6/8/23|7 - 9 pm PST|Each member should continue coming up with ideas to finalize the discussion section (all)|During this meeting we will discuss everyone’s suggestions for finalizing the discussion section and aim to get it fully completed|\n",
    "|Monday, 6/12/23|7 - 9 pm PST|Each member should come up with any suggestions for changes they may want to make to our final project (all).|We will discuss any changes people may want to make to the final project and work on finalizing the project for submission including all sections from the title to the conclusion. If not finished, we will continue working on Tuesday and we would ideally like to have our final project checkpoint submitted by Tuesday, 6/13/23 11:59 pm PST.|\n",
    "|Wednesday, 6/14/23 Group - Final project due (assuming at 8 pm PST) Individual - Team evaluations surveys due (assuming at 8 pm PST) | 4 - 6 pm PST (if meeting is needed)|Each member should come prepared with a list of any last minute concerns, questions, or edits they would like to make to the final project if we have not already submitted the project. (all) |Any last minute concerns, questions, or suggested edits for the final project that any person may have will be discussed (If project has not already been submitted). We will keep a goal to submit the project by 6 pm PST at the very, very, latest if absolutely needed.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"WHO\"></a>1.[^](#WHO): World Health Organization: https://www.who.int/health-topics/diabetes#tab=tab_1.<br> \n",
    "<a name=\"SMC\"></a>2.[^](#SMC): South Side Medical Center: https://southsidemedical.net/diabetes-management-why-is-it-important/#:~:text=Diabetes%20is%20a%20serious%20medical,%2C%20dementia%2C%20and%20kidney%20issues. <br>\n",
    "<a name=\"Kaur&Kumari\"></a>3.[^](#Kaur&Kumari): Predictive modelling and analytics for diabetes using a machine learning approach: https://www.emerald.com/insight/content/doi/10.1016/j.aci.2018.12.004/full/html.  <br>\n",
    "<a name=\"Spanig\"></a>4.[^](#Spanig): The virtual doctor: An interactive clinical-decision-support system based on deep learning for non-invasive prediction of diabetes: https://www.sciencedirect.com/science/article/pii/S0933365719301083?casa_token=cOj_UY-zjeMAAAAA:elRBENnAuVFx6T2Mk5wh0s9KE4fJF5_vokrfuxv1f_a_g8MZClm28_pSu6hkm4M6sbnnIxPp0w. <br>\n",
    "<a name=\"Garg\"></a>5.[^](#Garg): Benchmark example on Kaggle: https://www.kaggle.com/code/ishantgargml/diabetes-prediction-96-99-accuracy-ann/notebook#Our-winning-model-is-ANN-with-96.99%-accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
